{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>model_wrong</th>\n",
       "      <th>db.model_preds</th>\n",
       "      <th>status</th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97457</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10001</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>False</td>\n",
       "      <td>0.08233</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10002</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.92319</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10003</td>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99006</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004</td>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98836</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                               text label  \\\n",
       "0           1  10000  It should be legal for a husband to rape his wife  hate   \n",
       "1           2  10001                            dalits are lowlife scum  hate   \n",
       "2           3  10002                                dalits are lowlives  hate   \n",
       "3           4  10003  It was a better world when women dare not ques...  hate   \n",
       "4           5  10004  I don't work this hard so that those immigrant...  hate   \n",
       "\n",
       "       type model_wrong  db.model_preds           status round  split  \\\n",
       "0  notgiven        True         0.97457  dynabench entry     1  train   \n",
       "1  notgiven       False         0.08233  dynabench entry     1   test   \n",
       "2  notgiven        True         0.92319  dynabench entry     1  train   \n",
       "3  notgiven        True         0.99006  dynabench entry     1   test   \n",
       "4  notgiven        True         0.98836  dynabench entry     1  train   \n",
       "\n",
       "    annotator  \n",
       "0  gnzuctwed3  \n",
       "1  cagnluiznm  \n",
       "2  cagnluiznm  \n",
       "3  gnzuctwed3  \n",
       "4  cagnluiznm  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        Unnamed: 0     id                                               text  \\\n",
       "0               1  10000  It should be legal for a husband to rape his wife   \n",
       "1               2  10001                            dalits are lowlife scum   \n",
       "2               3  10002                                dalits are lowlives   \n",
       "3               4  10003  It was a better world when women dare not ques...   \n",
       "4               5  10004  I don't work this hard so that those immigrant...   \n",
       "...           ...    ...                                                ...   \n",
       "40618       40736   9995  we should forcibly remove all the foreigners f...   \n",
       "40619       40737   9996  we should forcibly remove all the immigrants f...   \n",
       "40620       40738   9997               dalits are unworthy of the Gods love   \n",
       "40621       40739   9998                               dalits are worthless   \n",
       "40622       40740   9999       dalits are deserves to be treated as lowlife   \n",
       "\n",
       "      label      type model_wrong  db.model_preds           status round  \\\n",
       "0      hate  notgiven        True         0.97457  dynabench entry     1   \n",
       "1      hate  notgiven       False         0.08233  dynabench entry     1   \n",
       "2      hate  notgiven        True         0.92319  dynabench entry     1   \n",
       "3      hate  notgiven        True         0.99006  dynabench entry     1   \n",
       "4      hate  notgiven        True         0.98836  dynabench entry     1   \n",
       "...     ...       ...         ...             ...              ...   ...   \n",
       "40618  hate  notgiven        True         0.86945  dynabench entry     1   \n",
       "40619  hate  notgiven        True         0.50039  dynabench entry     1   \n",
       "40620  hate  notgiven        True         0.97652  dynabench entry     1   \n",
       "40621  hate  notgiven        True         0.94326  dynabench entry     1   \n",
       "40622  hate  notgiven        True         0.94324  dynabench entry     1   \n",
       "\n",
       "       split   annotator  \n",
       "0      train  gnzuctwed3  \n",
       "1       test  cagnluiznm  \n",
       "2      train  cagnluiznm  \n",
       "3       test  gnzuctwed3  \n",
       "4      train  cagnluiznm  \n",
       "...      ...         ...  \n",
       "40618  train  cagnluiznm  \n",
       "40619  train  cagnluiznm  \n",
       "40620  train  cagnluiznm  \n",
       "40621  train  cagnluiznm  \n",
       "40622  train  cagnluiznm  \n",
       "\n",
       "[40623 rows x 11 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40623, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>model_wrong</th>\n",
       "      <th>db.model_preds</th>\n",
       "      <th>status</th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40623.000000</td>\n",
       "      <td>40623</td>\n",
       "      <td>40623</td>\n",
       "      <td>40623</td>\n",
       "      <td>40623</td>\n",
       "      <td>26097</td>\n",
       "      <td>26097.000000</td>\n",
       "      <td>40623</td>\n",
       "      <td>40623</td>\n",
       "      <td>40623</td>\n",
       "      <td>40623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40623</td>\n",
       "      <td>40463</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24773</td>\n",
       "      <td>Blacks are such pondlife</td>\n",
       "      <td>hate</td>\n",
       "      <td>none</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22124</td>\n",
       "      <td>18499</td>\n",
       "      <td>15436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26097</td>\n",
       "      <td>11542</td>\n",
       "      <td>32497</td>\n",
       "      <td>6733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20371.983236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11743.590183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.448801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10206.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20374.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30534.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40740.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0     id                      text  label   type  \\\n",
       "count   40623.000000  40623                     40623  40623  40623   \n",
       "unique           NaN  40623                     40463      2      7   \n",
       "top              NaN  24773  Blacks are such pondlife   hate   none   \n",
       "freq             NaN      1                         6  22124  18499   \n",
       "mean    20371.983236    NaN                       NaN    NaN    NaN   \n",
       "std     11743.590183    NaN                       NaN    NaN    NaN   \n",
       "min         1.000000    NaN                       NaN    NaN    NaN   \n",
       "25%     10206.500000    NaN                       NaN    NaN    NaN   \n",
       "50%     20374.000000    NaN                       NaN    NaN    NaN   \n",
       "75%     30534.500000    NaN                       NaN    NaN    NaN   \n",
       "max     40740.000000    NaN                       NaN    NaN    NaN   \n",
       "\n",
       "       model_wrong  db.model_preds           status  round  split   annotator  \n",
       "count        26097    26097.000000            40623  40623  40623       40623  \n",
       "unique           2             NaN                2      5      3          20  \n",
       "top           True             NaN  dynabench entry      1  train  gnzuctwed3  \n",
       "freq         15436             NaN            26097  11542  32497        6733  \n",
       "mean           NaN        0.585455              NaN    NaN    NaN         NaN  \n",
       "std            NaN        0.448801              NaN    NaN    NaN         NaN  \n",
       "min            NaN        0.000010              NaN    NaN    NaN         NaN  \n",
       "25%            NaN        0.036560              NaN    NaN    NaN         NaN  \n",
       "50%            NaN        0.910290              NaN    NaN    NaN         NaN  \n",
       "75%            NaN        0.995500              NaN    NaN    NaN         NaN  \n",
       "max            NaN        0.999920              NaN    NaN    NaN         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'text', 'label', 'type', 'model_wrong',\n",
       "       'db.model_preds', 'status', 'round', 'split', 'annotator'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport\n",
    "# profile = ProfileReport(data)\n",
    "# profile.to_file('EDA.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # importing sweetviz\n",
    "# import sweetviz as sv\n",
    "# #analyzing the dataset\n",
    "# advert_report = sv.analyze(data)\n",
    "# #display the report\n",
    "# advert_report.show_html('auto_eda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>model_wrong</th>\n",
       "      <th>db.model_preds</th>\n",
       "      <th>status</th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97457</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10001</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>False</td>\n",
       "      <td>0.08233</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10002</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.92319</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10003</td>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99006</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004</td>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98836</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>10005</td>\n",
       "      <td>I don't work this hard so that those migrants ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99506</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>10006</td>\n",
       "      <td>I don't work this hard so that those foreigner...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99340</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>10007</td>\n",
       "      <td>I don't work this hard so that those Hispanics...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98625</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>10008</td>\n",
       "      <td>I don't work this hard so that those chavs can...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95252</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10009</td>\n",
       "      <td>I don't work this hard so that all those pakis...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>False</td>\n",
       "      <td>0.09288</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                               text label  \\\n",
       "0           1  10000  It should be legal for a husband to rape his wife  hate   \n",
       "1           2  10001                            dalits are lowlife scum  hate   \n",
       "2           3  10002                                dalits are lowlives  hate   \n",
       "3           4  10003  It was a better world when women dare not ques...  hate   \n",
       "4           5  10004  I don't work this hard so that those immigrant...  hate   \n",
       "5           6  10005  I don't work this hard so that those migrants ...  hate   \n",
       "6           7  10006  I don't work this hard so that those foreigner...  hate   \n",
       "7           8  10007  I don't work this hard so that those Hispanics...  hate   \n",
       "8           9  10008  I don't work this hard so that those chavs can...  hate   \n",
       "9          10  10009  I don't work this hard so that all those pakis...  hate   \n",
       "\n",
       "       type model_wrong  db.model_preds           status round  split  \\\n",
       "0  notgiven        True         0.97457  dynabench entry     1  train   \n",
       "1  notgiven       False         0.08233  dynabench entry     1   test   \n",
       "2  notgiven        True         0.92319  dynabench entry     1  train   \n",
       "3  notgiven        True         0.99006  dynabench entry     1   test   \n",
       "4  notgiven        True         0.98836  dynabench entry     1  train   \n",
       "5  notgiven        True         0.99506  dynabench entry     1  train   \n",
       "6  notgiven        True         0.99340  dynabench entry     1  train   \n",
       "7  notgiven        True         0.98625  dynabench entry     1  train   \n",
       "8  notgiven        True         0.95252  dynabench entry     1   test   \n",
       "9  notgiven       False         0.09288  dynabench entry     1  train   \n",
       "\n",
       "    annotator  \n",
       "0  gnzuctwed3  \n",
       "1  cagnluiznm  \n",
       "2  cagnluiznm  \n",
       "3  gnzuctwed3  \n",
       "4  cagnluiznm  \n",
       "5  cagnluiznm  \n",
       "6  cagnluiznm  \n",
       "7  cagnluiznm  \n",
       "8  cagnluiznm  \n",
       "9  cagnluiznm  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  It should be legal for a husband to rape his wife  hate\n",
       "1                            dalits are lowlife scum  hate\n",
       "2                                dalits are lowlives  hate\n",
       "3  It was a better world when women dare not ques...  hate\n",
       "4  I don't work this hard so that those immigrant...  hate"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "data['label'] = le.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22124\n",
       "1    18499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text): \n",
    "    # changing to lower case\n",
    "    lower = text.str.lower()\n",
    "    \n",
    "    # Replacing the repeating pattern of &#039;\n",
    "    pattern_remove = lower.str.replace(\"&#039;\", \"\")\n",
    "    \n",
    "    # Removing all the special Characters\n",
    "    special_remove = pattern_remove.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "    \n",
    "    # Removing all the non ASCII characters\n",
    "    ascii_remove = special_remove.str.replace(r'[^\\x00-\\x7F]+',' ')\n",
    "    \n",
    "    # Removing the leading and trailing Whitespaces\n",
    "    whitespace_remove = ascii_remove.str.replace(r'^\\s+|\\s+?$','')\n",
    "    \n",
    "    # Replacing multiple Spaces with Single Space\n",
    "    multiw_remove = whitespace_remove.str.replace(r'\\s+',' ')\n",
    "    \n",
    "    # Replacing Two or more dots with one\n",
    "    dataframe = multiw_remove.str.replace(r'\\.{2,}', ' ')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['text_clean'] = text_clean(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>0</td>\n",
       "      <td>it should be legal for a husband to rape his wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>0</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>0</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>0</td>\n",
       "      <td>it was a better world when women dare not ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>0</td>\n",
       "      <td>i don t work this hard so that those immigrant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  It should be legal for a husband to rape his wife      0   \n",
       "1                            dalits are lowlife scum      0   \n",
       "2                                dalits are lowlives      0   \n",
       "3  It was a better world when women dare not ques...      0   \n",
       "4  I don't work this hard so that those immigrant...      0   \n",
       "\n",
       "                                          text_clean  \n",
       "0  it should be legal for a husband to rape his wife  \n",
       "1                            dalits are lowlife scum  \n",
       "2                                dalits are lowlives  \n",
       "3  it was a better world when women dare not ques...  \n",
       "4  i don t work this hard so that those immigrant...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['text_clean']\n",
    "y= data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (28436,)\n",
      "Number transactions y_train dataset:  (28436,)\n",
      "Number transactions X_test dataset:  (12187,)\n",
      "Number transactions y_test dataset:  (12187,)\n"
     ]
    }
   ],
   "source": [
    "# describes info about train and test set\n",
    "print(\"Number transactions X_train dataset: \", x_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", x_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hvectorizer = HashingVectorizer(n_features=10000,norm=None,alternate_sign=False,stop_words='english') \n",
    "x_train = hvectorizer.fit_transform(x_train).toarray()\n",
    "x_test = hvectorizer.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23359    1\n",
       "25447    0\n",
       "36655    0\n",
       "34190    1\n",
       "4946     0\n",
       "        ..\n",
       "36894    1\n",
       "29369    1\n",
       "3465     0\n",
       "10897    0\n",
       "25667    1\n",
       "Name: label, Length: 28436, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained by the Logistic Regression is:  0.7038647739394437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "# training the model\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "acc_lr = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print('The accuracy obtained by the Logistic Regression is: ',acc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Entered Text is Detected as Hate Speech\n"
     ]
    }
   ],
   "source": [
    "result = lr.predict(hvectorizer.transform(['''Women are so oversensitive''']))\n",
    "if result==0:\n",
    "    print(\"The Entered Text is Detected as Hate Speech\")\n",
    "else:\n",
    "    print(\"The Entered Text is Detected as NO-Hate Speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Entered Text is Detected as No-Hate Speech\n"
     ]
    }
   ],
   "source": [
    "result = lr.predict(hvectorizer.transform(['''my meal was fucking disgusting''']))\n",
    "if result==0:\n",
    "    print(\"The Entered Text is Detected as Hate Speech\")\n",
    "else:\n",
    "    print(\"The Entered Text is Detected as No-Hate Speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6426520062361533"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(x_train,y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "acc  = accuracy_score(y_test,y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Entered Text is Detected as No-Hate Speech\n"
     ]
    }
   ],
   "source": [
    "result = dt.predict(hvectorizer.transform(['''who ever will oppose me i will kill them ''']))\n",
    "if result==0:\n",
    "    print(\"The Entered Text is Detected as Hate Speech\")\n",
    "else:\n",
    "    print(\"The Entered Text is Detected as No-Hate Speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6503651431853614"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb = nb.fit(x_train,y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "acc  = accuracy_score(y_test,y_pred)\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# adb = AdaBoostClassifier()\n",
    "# adb = adb.fit(x_train,y_train)\n",
    "# y_pred = adb.predict(x_test)\n",
    "# acc  = accuracy_score(y_test,y_pred)\n",
    "# acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28436, 10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 160,193\n",
      "Trainable params: 160,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.6826 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.5446\n",
      "Epoch 2/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.6419 - accuracy: 0.6180 - val_loss: 0.6201 - val_accuracy: 0.6807\n",
      "Epoch 3/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.6025 - accuracy: 0.6432 - val_loss: 0.5961 - val_accuracy: 0.6899\n",
      "Epoch 4/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.5635 - accuracy: 0.6676 - val_loss: 0.5892 - val_accuracy: 0.6966\n",
      "Epoch 5/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.5323 - accuracy: 0.7184 - val_loss: 0.5935 - val_accuracy: 0.6940\n",
      "Epoch 6/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.5081 - accuracy: 0.7322 - val_loss: 0.5980 - val_accuracy: 0.6987\n",
      "Epoch 7/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.4875 - accuracy: 0.7483 - val_loss: 0.6219 - val_accuracy: 0.6990\n",
      "Epoch 8/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.4705 - accuracy: 0.7563 - val_loss: 0.6369 - val_accuracy: 0.6948\n",
      "Epoch 9/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.4493 - accuracy: 0.7631 - val_loss: 0.6866 - val_accuracy: 0.6992\n",
      "Epoch 10/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.4306 - accuracy: 0.7774 - val_loss: 0.7178 - val_accuracy: 0.6980\n",
      "Epoch 11/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.4168 - accuracy: 0.7839 - val_loss: 0.7660 - val_accuracy: 0.6970\n",
      "Epoch 12/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.4038 - accuracy: 0.7894 - val_loss: 0.8207 - val_accuracy: 0.6956\n",
      "Epoch 13/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3921 - accuracy: 0.7941 - val_loss: 0.8997 - val_accuracy: 0.6953\n",
      "Epoch 14/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3816 - accuracy: 0.8001 - val_loss: 0.9581 - val_accuracy: 0.6975\n",
      "Epoch 15/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3698 - accuracy: 0.8050 - val_loss: 1.0636 - val_accuracy: 0.6960\n",
      "Epoch 16/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3616 - accuracy: 0.8111 - val_loss: 1.0811 - val_accuracy: 0.6948\n",
      "Epoch 17/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3565 - accuracy: 0.8127 - val_loss: 1.1556 - val_accuracy: 0.6934\n",
      "Epoch 18/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3495 - accuracy: 0.8166 - val_loss: 1.2228 - val_accuracy: 0.6911\n",
      "Epoch 19/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3453 - accuracy: 0.8169 - val_loss: 1.3136 - val_accuracy: 0.6908\n",
      "Epoch 20/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3372 - accuracy: 0.8216 - val_loss: 1.3913 - val_accuracy: 0.6933\n",
      "Epoch 21/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3319 - accuracy: 0.8206 - val_loss: 1.4728 - val_accuracy: 0.6952\n",
      "Epoch 22/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3350 - accuracy: 0.8210 - val_loss: 1.5543 - val_accuracy: 0.6970\n",
      "Epoch 23/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3272 - accuracy: 0.8256 - val_loss: 1.5798 - val_accuracy: 0.6952\n",
      "Epoch 24/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3226 - accuracy: 0.8310 - val_loss: 1.5834 - val_accuracy: 0.6931\n",
      "Epoch 25/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3170 - accuracy: 0.8312 - val_loss: 1.6779 - val_accuracy: 0.6945\n",
      "Epoch 26/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3166 - accuracy: 0.8319 - val_loss: 1.6350 - val_accuracy: 0.6925\n",
      "Epoch 27/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.3175 - accuracy: 0.8308 - val_loss: 1.8299 - val_accuracy: 0.6926108 - accuracy - ETA: 1s - loss: 0.3109 - accuracy:  - E\n",
      "Epoch 28/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3091 - accuracy: 0.8384 - val_loss: 1.7813 - val_accuracy: 0.6936\n",
      "Epoch 29/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.3015 - accuracy: 0.8357 - val_loss: 2.0361 - val_accuracy: 0.6934\n",
      "Epoch 30/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.2618 - accuracy: 0.8360 - val_loss: 2.0466 - val_accuracy: 0.6918\n",
      "Epoch 31/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2561 - accuracy: 0.8503 - val_loss: 2.0711 - val_accuracy: 0.6907\n",
      "Epoch 32/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2499 - accuracy: 0.8610 - val_loss: 2.2157 - val_accuracy: 0.6916\n",
      "Epoch 33/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2481 - accuracy: 0.8591 - val_loss: 2.3275 - val_accuracy: 0.6916\n",
      "Epoch 34/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2441 - accuracy: 0.8626 - val_loss: 2.3228 - val_accuracy: 0.6896\n",
      "Epoch 35/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2400 - accuracy: 0.8603 - val_loss: 2.5058 - val_accuracy: 0.6888\n",
      "Epoch 36/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2405 - accuracy: 0.8591 - val_loss: 2.5546 - val_accuracy: 0.6902\n",
      "Epoch 37/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2343 - accuracy: 0.8657 - val_loss: 2.7310 - val_accuracy: 0.6884\n",
      "Epoch 38/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2325 - accuracy: 0.8666 - val_loss: 2.7034 - val_accuracy: 0.6912\n",
      "Epoch 39/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2303 - accuracy: 0.8648 - val_loss: 2.9145 - val_accuracy: 0.6924\n",
      "Epoch 40/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2277 - accuracy: 0.8651 - val_loss: 2.9958 - val_accuracy: 0.6875\n",
      "Epoch 41/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2322 - accuracy: 0.8662 - val_loss: 2.9992 - val_accuracy: 0.6900\n",
      "Epoch 42/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2259 - accuracy: 0.8656 - val_loss: 3.2370 - val_accuracy: 0.6891\n",
      "Epoch 43/50\n",
      "889/889 [==============================] - 2s 2ms/step - loss: 0.2305 - accuracy: 0.8653 - val_loss: 3.0546 - val_accuracy: 0.6891\n",
      "Epoch 44/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2236 - accuracy: 0.8678 - val_loss: 3.2118 - val_accuracy: 0.6894\n",
      "Epoch 45/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2244 - accuracy: 0.8670 - val_loss: 3.2217 - val_accuracy: 0.6879\n",
      "Epoch 46/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2246 - accuracy: 0.8661 - val_loss: 3.3251 - val_accuracy: 0.6896\n",
      "Epoch 47/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2275 - accuracy: 0.8633 - val_loss: 3.3622 - val_accuracy: 0.6924\n",
      "Epoch 48/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2245 - accuracy: 0.8675 - val_loss: 3.3160 - val_accuracy: 0.6908\n",
      "Epoch 49/50\n",
      "889/889 [==============================] - 2s 3ms/step - loss: 0.2294 - accuracy: 0.8666 - val_loss: 3.2184 - val_accuracy: 0.6924\n",
      "Epoch 50/50\n",
      "889/889 [==============================] - 3s 3ms/step - loss: 0.2188 - accuracy: 0.8684 - val_loss: 3.2762 - val_accuracy: 0.6941\n",
      "The accuracy obtained by ANN model : 68.97234737873077\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# layers\n",
    "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10000))\n",
    "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "# from keras.optimizers import SGD\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "# fit the model to the training data\n",
    "history=model.fit(x_train, y_train,epochs=50, validation_data=(x_test, y_test))\n",
    "y_pred = model.predict(x_test)\n",
    "acc_cnn = np.mean(history.history['val_accuracy'])\n",
    "\n",
    "acc_cnn = acc_cnn*100\n",
    "print('The accuracy obtained by ANN model :',acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4e9cda46bb2d9d7fe6ecdff0f8336a934348bf06cb492f2f42f60739b3403b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
